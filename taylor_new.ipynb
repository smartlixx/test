{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!/usr/bin/env python\n",
      "\n",
      "__version__ = \"Time-stamp: <2012-08-13 16:52 ycopin@lyopc469>\"\n",
      "__author__ = \"Yannick Copin <yannick.copin@laposte.net>\"\n",
      "\n",
      "\"\"\"\n",
      "Example of use of TaylorDiagram. Illustration dataset courtesy of\n",
      "Michael Rawlins.\n",
      "\n",
      "Rawlins, M. A., R. S. Bradley, H. F. Diaz, 2012. Assessment of\n",
      "regional climate model simulation estimates over the Northeast U.S.,\n",
      "Journal of Geophysical Research, in review.\n",
      "\"\"\"\n",
      "\n",
      "import sys\n",
      "sys.path.insert(0,'/home/liuxuan/ucm/add_tree/paper_need/taylor')\n",
      "from taylorDiagram import TaylorDiagram\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import datetime as dt\n",
      "import matplotlib.dates as mdates\n",
      "import pytz\n",
      "import scipy.io.netcdf as nc\n",
      "import pandas as pd\n",
      "import math\n",
      "\n",
      "dateparse = lambda x: pd.datetime.strptime(x,'%Y %j %H %M')\n",
      "FluxData = pd.read_csv('/home/liuxuan/ucm/data_analysize/FLUXTS_242_2010-110_2014.dat',\n",
      "                       header=0, \n",
      "                       skiprows=1,\n",
      "                       delim_whitespace=True, \n",
      "                       skipinitialspace=True,\n",
      "                       parse_dates={'Time':['year','Day','H','P']},\n",
      "                       index_col='Time',\n",
      "                       usecols=['year','Day','H','P','H(W/m2)','HL(W/m2)','Qnet(W/m2)','Kup(W/m2)','Lup(W/m2)'],\n",
      "                       na_values=[-999],\n",
      "                       date_parser=dateparse)\n",
      "FluxData = FluxData['2013-05-18 01:00:00':'2014-04-19 01:00:00']\n",
      "FluxData.index = FluxData.index.tz_localize(pytz.timezone('Asia/Singapore'))\n",
      "FluxData[FluxData.isnull().sum(1)>0] = np.nan\n",
      "#FluxData.loc[FluxData['HL(W/m2)']<0,'HL(W/m2)'] = 0.0\n",
      "FluxData.loc[FluxData['HL(W/m2)']<0] = np.nan\n",
      "qs_obs = FluxData['Qnet(W/m2)']-FluxData['H(W/m2)']-FluxData['HL(W/m2)']\n",
      "FluxData['Qstor(W/m2)'] = qs_obs\n",
      "\n",
      "\n",
      "                        \n",
      "# input modeled data\n",
      "nc_file = nc.netcdf_file('OUTPUT1.nc','r')    # OUTPUT.nc from model\n",
      "time = nc_file.variables['Times'][0::2]\n",
      "time_str = map(''.join,time)\n",
      "time_final = [pd.datetime.strptime(t, '%Y%m%d%H%M').replace(tzinfo=pytz.utc).astimezone(pytz.timezone('Asia/Singapore')) for t in time_str]\n",
      "lh = nc_file.variables['Qle'][0::2]     # total latent heat flux   \n",
      "sh = nc_file.variables['Qh'][0::2]      # total sensible heat flux\n",
      "rn = nc_file.variables['Rnet'][0::2]    # total net all wave radiation\n",
      "sw = nc_file.variables['SWup'][0::2]      # upward shortwave radiation\n",
      "lw = nc_file.variables['LWup'][0::2]    # upward longwave radiation\n",
      "qs = nc_file.variables['Qstor'][0::2]   # heat storage\n",
      "output_data = pd.DataFrame(np.transpose([time_final, sh, lh, rn, sw, lw, qs]),\n",
      "                           columns=['Time','H(W/m2)','HL(W/m2)','Qnet(W/m2)','Kup(W/m2)','Lup(W/m2)','Qstor(W/m2)'])\n",
      "output_data = output_data.set_index('Time')\n",
      "output_data = output_data.astype('float64')\n",
      "output_data1 = output_data\n",
      "#output_data = (output_data-FluxData).dropna()+FluxData\n",
      "output_data[FluxData.isnull().sum(1)>0] = np.nan\n",
      "output_data1 = output_data.dropna()\n",
      "\n",
      "\n",
      "\n",
      "nc_file2 = nc.netcdf_file('OUTPUT2.nc','r')    # OUTPUT.nc from model\n",
      "lh2 = nc_file2.variables['Qle'][0::2]     # total latent heat flux   \n",
      "sh2 = nc_file2.variables['Qh'][0::2]      # total sensible heat flux\n",
      "rn2 = nc_file2.variables['Rnet'][0::2]    # total net all wave radiation\n",
      "sw2 = nc_file2.variables['SWup'][0::2]\n",
      "lw2 = nc_file2.variables['LWup'][0::2]\n",
      "qs2 = nc_file2.variables['Qstor'][0::2]\n",
      "output_data2 = pd.DataFrame(np.transpose([time_final, sh2, lh2,rn2,sw2,lw2,qs2]),\n",
      "                            columns=['Time','H(W/m2)','HL(W/m2)','Qnet(W/m2)','Kup(W/m2)','Lup(W/m2)','Qstor(W/m2)'])\n",
      "output_data2 = output_data2.set_index('Time')\n",
      "output_data2 = output_data2.astype('float64')\n",
      "output_data2 = output_data2\n",
      "output_data2[FluxData.isnull().sum(1)>0] = np.nan\n",
      "output_data2 = output_data2.dropna()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nc_file3 = nc.netcdf_file('OUTPUT3.nc','r')    # OUTPUT.nc from model\n",
      "lh3 = nc_file3.variables['Qle'][0::2]     # total latent heat flux   \n",
      "sh3 = nc_file3.variables['Qh'][0::2]      # total sensible heat flux\n",
      "rn3 = nc_file3.variables['Rnet'][0::2]    # total net all wave radiation\n",
      "sw3 = nc_file3.variables['SWup'][0::2]\n",
      "lw3 = nc_file3.variables['LWup'][0::2]\n",
      "qs3 = nc_file3.variables['Qstor'][0::2]\n",
      "output_data3 = pd.DataFrame(np.transpose([time_final, sh3, lh3,rn3,sw3,lw3,qs3]),\n",
      "                            columns=['Time','H(W/m2)','HL(W/m2)','Qnet(W/m2)','Kup(W/m2)','Lup(W/m2)','Qstor(W/m2)'])\n",
      "output_data3 = output_data3.set_index('Time')\n",
      "output_data3 = output_data3.astype('float64')\n",
      "output_data3 = output_data3\n",
      "output_data3[FluxData.isnull().sum(1)>0] = np.nan\n",
      "output_data3 = output_data3.dropna()\n",
      "\n",
      "\n",
      "FluxData = FluxData.dropna()\n",
      "R1 = ((output_data1-output_data1.mean())*(FluxData-FluxData.mean())).mean()/(output_data1.std()*FluxData.std())\n",
      "R2 = ((output_data2-output_data2.mean())*(FluxData-FluxData.mean())).mean()/(output_data2.std()*FluxData.std())\n",
      "R3 = ((output_data3-output_data3.mean())*(FluxData-FluxData.mean())).mean()/(output_data3.std()*FluxData.std())\n",
      "print R1,R2,R3\n",
      "\n",
      "FluxData_sw = FluxData['2013-05-31 16:30:00':'2013-10-15 15:30:00']\n",
      "output_data1_sw = output_data1['2013-05-31 16:30:00':'2013-10-15 15:30:00']\n",
      "output_data2_sw = output_data2['2013-05-31 16:30:00':'2013-10-15 15:30:00']\n",
      "output_data3_sw = output_data3['2013-05-31 16:30:00':'2013-10-15 15:30:00']\n",
      "R1_sw = ((output_data1_sw-output_data1_sw.mean())*(FluxData_sw-FluxData_sw.mean())).mean()/(output_data1_sw.std()*FluxData_sw.std())\n",
      "R2_sw = ((output_data2_sw-output_data2_sw.mean())*(FluxData_sw-FluxData_sw.mean())).mean()/(output_data2_sw.std()*FluxData_sw.std())\n",
      "R3_sw = ((output_data3_sw-output_data3_sw.mean())*(FluxData_sw-FluxData_sw.mean())).mean()/(output_data3_sw.std()*FluxData_sw.std())\n",
      "FluxData_ne = FluxData['2013-11-15 16:30:00':'2014-01-12 15:30:00']\n",
      "output_data1_ne = output_data1['2013-11-15 16:30:00':'2014-01-12 15:30:00']\n",
      "output_data2_ne = output_data2['2013-11-15 16:30:00':'2014-01-12 15:30:00']\n",
      "output_data3_ne = output_data3['2013-11-15 16:30:00':'2014-01-12 15:30:00']\n",
      "R1_ne = ((output_data1_ne-output_data1_ne.mean())*(FluxData_ne-FluxData_ne.mean())).mean()/(output_data1_ne.std()*FluxData_ne.std())\n",
      "R2_ne = ((output_data2_ne-output_data2_ne.mean())*(FluxData_ne-FluxData_ne.mean())).mean()/(output_data2_ne.std()*FluxData_ne.std())\n",
      "R3_ne = ((output_data3_ne-output_data3_ne.mean())*(FluxData_ne-FluxData_ne.mean())).mean()/(output_data3_ne.std()*FluxData_ne.std())\n",
      "FluxData_dry = FluxData['2014-01-12 16:30:00':'2014-03-15 15:30:00']\n",
      "output_data1_dry = output_data1['2014-01-12 16:30:00':'2014-03-15 15:30:00']\n",
      "output_data2_dry = output_data2['2014-01-12 16:30:00':'2014-03-15 15:30:00']\n",
      "output_data3_dry = output_data3['2014-01-12 16:30:00':'2014-03-15 15:30:00']\n",
      "R1_dry = ((output_data1_dry-output_data1_dry.mean())*(FluxData_dry-FluxData_dry.mean())).mean()/(output_data1_dry.std()*FluxData_dry.std())\n",
      "R2_dry = ((output_data2_dry-output_data2_dry.mean())*(FluxData_dry-FluxData_dry.mean())).mean()/(output_data2_dry.std()*FluxData_dry.std())\n",
      "R3_dry = ((output_data3_dry-output_data3_dry.mean())*(FluxData_dry-FluxData_dry.mean())).mean()/(output_data3_dry.std()*FluxData_dry.std())\n",
      "print FluxData_dry.std()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "H(W/m2)        0.933929\n",
        "HL(W/m2)       0.550022\n",
        "Kup(W/m2)      0.993898\n",
        "Lup(W/m2)      0.972619\n",
        "Qnet(W/m2)     0.997676\n",
        "Qstor(W/m2)    0.869901\n",
        "dtype: float64 H(W/m2)        0.934059\n",
        "HL(W/m2)       0.543155\n",
        "Kup(W/m2)      0.993898\n",
        "Lup(W/m2)      0.972766\n",
        "Qnet(W/m2)     0.997731\n",
        "Qstor(W/m2)    0.869372\n",
        "dtype: float64 H(W/m2)        0.926197\n",
        "HL(W/m2)       0.640321\n",
        "Kup(W/m2)      0.993898\n",
        "Lup(W/m2)      0.972560\n",
        "Qnet(W/m2)     0.997937\n",
        "Qstor(W/m2)    0.867327\n",
        "dtype: float64\n",
        "H(W/m2)        115.284711\n",
        "HL(W/m2)        36.295735\n",
        "Kup(W/m2)       50.031705\n",
        "Lup(W/m2)       29.670983\n",
        "Qnet(W/m2)     248.278438\n",
        "Qstor(W/m2)    119.573615\n",
        "dtype: float64\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Reference std\n",
      "stdrefs = dict(QE=FluxData['HL(W/m2)'].std(),\n",
      "               QH=FluxData['H(W/m2)'].std(),\n",
      "               QN=FluxData['Qnet(W/m2)'].std())\n",
      "names = dict(QE=r'Q$_E$',\n",
      "             QH=r'Q$_H$',\n",
      "             QN=r'Q$^*$ & L$\\uparrow$')\n",
      "\n",
      "\n",
      "# Sample std,rho: Be sure to check order and that correct numbers are placed!\n",
      "samples = dict(QE    =[[output_data1['HL(W/m2)'].std(), R1['HL(W/m2)'], \"SIM 1_total\"],\n",
      "                       [output_data2['HL(W/m2)'].std(), R2['HL(W/m2)'], \"SIM 2_total\"],\n",
      "                       [output_data3['HL(W/m2)'].std(), R3['HL(W/m2)'], \"SIM 3_total\"],\n",
      "                       [output_data1_sw['HL(W/m2)'].std()*FluxData['HL(W/m2)'].std()/FluxData_sw['HL(W/m2)'].std(), R1_sw['HL(W/m2)'], \"SIM 1_sw\"],\n",
      "                       [output_data2_sw['HL(W/m2)'].std()*FluxData['HL(W/m2)'].std()/FluxData_sw['HL(W/m2)'].std(), R2_sw['HL(W/m2)'], \"SIM 2_sw\"],\n",
      "                       [output_data3_sw['HL(W/m2)'].std()*FluxData['HL(W/m2)'].std()/FluxData_sw['HL(W/m2)'].std(), R3_sw['HL(W/m2)'], \"SIM 3_sw\"],\n",
      "                       [output_data1_ne['HL(W/m2)'].std()*FluxData['HL(W/m2)'].std()/FluxData_ne['HL(W/m2)'].std(), R1_ne['HL(W/m2)'], \"SIM 1_ne\"],\n",
      "                       [output_data2_ne['HL(W/m2)'].std()*FluxData['HL(W/m2)'].std()/FluxData_ne['HL(W/m2)'].std(), R2_ne['HL(W/m2)'], \"SIM 2_ne\"],\n",
      "                       [output_data3_ne['HL(W/m2)'].std()*FluxData['HL(W/m2)'].std()/FluxData_ne['HL(W/m2)'].std(), R3_ne['HL(W/m2)'], \"SIM 3_ne\"],\n",
      "                       [output_data1_dry['HL(W/m2)'].std()*FluxData['HL(W/m2)'].std()/FluxData_dry['HL(W/m2)'].std(), R1_dry['HL(W/m2)'], \"SIM 1_dry\"],\n",
      "                       [output_data2_dry['HL(W/m2)'].std()*FluxData['HL(W/m2)'].std()/FluxData_dry['HL(W/m2)'].std(), R2_dry['HL(W/m2)'], \"SIM 2_dry\"],\n",
      "                       [output_data3_dry['HL(W/m2)'].std()*FluxData['HL(W/m2)'].std()/FluxData_dry['HL(W/m2)'].std(), R3_dry['HL(W/m2)'], \"SIM 3_dry\"],\n",
      "                       ],\n",
      "               QH   = [[output_data1['H(W/m2)'].std(), R1['H(W/m2)'], \"SIM 1_total\"],\n",
      "                       [output_data2['H(W/m2)'].std(), R2['H(W/m2)'], \"SIM 2_total\"],\n",
      "                       [output_data3['H(W/m2)'].std(), R3['H(W/m2)'], \"SIM 3_total\"],\n",
      "                       [output_data1_sw['H(W/m2)'].std()*FluxData['H(W/m2)'].std()/FluxData_sw['H(W/m2)'].std(), R1_sw['H(W/m2)'], \"SIM 1_sw\"],\n",
      "                       [output_data2_sw['H(W/m2)'].std()*FluxData['H(W/m2)'].std()/FluxData_sw['H(W/m2)'].std(), R2_sw['H(W/m2)'], \"SIM 2_sw\"],\n",
      "                       [output_data3_sw['H(W/m2)'].std()*FluxData['H(W/m2)'].std()/FluxData_sw['H(W/m2)'].std(), R3_sw['H(W/m2)'], \"SIM 3_sw\"],\n",
      "                       [output_data1_ne['H(W/m2)'].std()*FluxData['H(W/m2)'].std()/FluxData_ne['H(W/m2)'].std(), R1_ne['H(W/m2)'], \"SIM 1_ne\"],\n",
      "                       [output_data2_ne['H(W/m2)'].std()*FluxData['H(W/m2)'].std()/FluxData_ne['H(W/m2)'].std(), R2_ne['H(W/m2)'], \"SIM 2_ne\"],\n",
      "                       [output_data3_ne['H(W/m2)'].std()*FluxData['H(W/m2)'].std()/FluxData_ne['H(W/m2)'].std(), R3_ne['H(W/m2)'], \"SIM 3_ne\"],\n",
      "                       [output_data1_dry['H(W/m2)'].std()*FluxData['H(W/m2)'].std()/FluxData_dry['H(W/m2)'].std(), R1_dry['H(W/m2)'], \"SIM 1_dry\"],\n",
      "                       [output_data2_dry['H(W/m2)'].std()*FluxData['H(W/m2)'].std()/FluxData_dry['H(W/m2)'].std(), R2_dry['H(W/m2)'], \"SIM 2_dry\"],\n",
      "                       [output_data3_dry['H(W/m2)'].std()*FluxData['H(W/m2)'].std()/FluxData_dry['H(W/m2)'].std(), R3_dry['H(W/m2)'], \"SIM 3_dry\"],\n",
      "                       ],\n",
      "               QN=    [[output_data1['Qnet(W/m2)'].std(), R1['Qnet(W/m2)'], \"SIM 1_total\"],\n",
      "                       [output_data2['Qnet(W/m2)'].std(), R2['Qnet(W/m2)'], \"SIM 2_total\"],\n",
      "                       [output_data3['Qnet(W/m2)'].std(), R3['Qnet(W/m2)'], \"SIM 3_total\"],\n",
      "                       [output_data1_sw['Qnet(W/m2)'].std()*FluxData['Qnet(W/m2)'].std()/FluxData_sw['Qnet(W/m2)'].std(), R1_sw['Qnet(W/m2)'], \"SIM 1_sw\"],\n",
      "                       [output_data2_sw['Qnet(W/m2)'].std()*FluxData['Qnet(W/m2)'].std()/FluxData_sw['Qnet(W/m2)'].std(), R2_sw['Qnet(W/m2)'], \"SIM 2_sw\"],\n",
      "                       [output_data3_sw['Qnet(W/m2)'].std()*FluxData['Qnet(W/m2)'].std()/FluxData_sw['Qnet(W/m2)'].std(), R3_sw['Qnet(W/m2)'], \"SIM 3_sw\"],\n",
      "                       [output_data1_ne['Qnet(W/m2)'].std()*FluxData['Qnet(W/m2)'].std()/FluxData_ne['Qnet(W/m2)'].std(), R1_ne['Qnet(W/m2)'], \"SIM 1_ne\"],\n",
      "                       [output_data2_ne['Qnet(W/m2)'].std()*FluxData['Qnet(W/m2)'].std()/FluxData_ne['Qnet(W/m2)'].std(), R2_ne['Qnet(W/m2)'], \"SIM 2_ne\"],\n",
      "                       [output_data3_ne['Qnet(W/m2)'].std()*FluxData['Qnet(W/m2)'].std()/FluxData_ne['Qnet(W/m2)'].std(), R3_ne['Qnet(W/m2)'], \"SIM 3_ne\"],\n",
      "                       [output_data1_dry['Qnet(W/m2)'].std()*FluxData['Qnet(W/m2)'].std()/FluxData_dry['Qnet(W/m2)'].std(), R1_dry['Qnet(W/m2)'], \"SIM 1_dry\"],\n",
      "                       [output_data2_dry['Qnet(W/m2)'].std()*FluxData['Qnet(W/m2)'].std()/FluxData_dry['Qnet(W/m2)'].std(), R2_dry['Qnet(W/m2)'], \"SIM 2_dry\"],\n",
      "                       [output_data3_dry['Qnet(W/m2)'].std()*FluxData['Qnet(W/m2)'].std()/FluxData_dry['Qnet(W/m2)'].std(), R3_dry['Qnet(W/m2)'], \"SIM 3_dry\"],\n",
      "                       [output_data1['Lup(W/m2)'].std()*FluxData['Qnet(W/m2)'].std()/FluxData['Lup(W/m2)'].std(), R1['Lup(W/m2)'], \"SIM 1_total\"],\n",
      "                       [output_data2['Lup(W/m2)'].std()*FluxData['Qnet(W/m2)'].std()/FluxData['Lup(W/m2)'].std(), R2['Lup(W/m2)'], \"SIM 2_total\"],\n",
      "                       [output_data3['Lup(W/m2)'].std()*FluxData['Qnet(W/m2)'].std()/FluxData['Lup(W/m2)'].std(), R3['Lup(W/m2)'], \"SIM 3_total\"],\n",
      "                       [output_data1_sw['Lup(W/m2)'].std()*FluxData['Qnet(W/m2)'].std()/FluxData_sw['Lup(W/m2)'].std(), R1_sw['Lup(W/m2)'], \"SIM 1_sw\"],\n",
      "                       [output_data2_sw['Lup(W/m2)'].std()*FluxData['Qnet(W/m2)'].std()/FluxData_sw['Lup(W/m2)'].std(), R2_sw['Lup(W/m2)'], \"SIM 2_sw\"],\n",
      "                       [output_data3_sw['Lup(W/m2)'].std()*FluxData['Qnet(W/m2)'].std()/FluxData_sw['Lup(W/m2)'].std(), R3_sw['Lup(W/m2)'], \"SIM 3_sw\"],\n",
      "                       [output_data1_ne['Lup(W/m2)'].std()*FluxData['Qnet(W/m2)'].std()/FluxData_ne['Lup(W/m2)'].std(), R1_ne['Lup(W/m2)'], \"SIM 1_ne\"],\n",
      "                       [output_data2_ne['Lup(W/m2)'].std()*FluxData['Qnet(W/m2)'].std()/FluxData_ne['Lup(W/m2)'].std(), R2_ne['Lup(W/m2)'], \"SIM 2_ne\"],\n",
      "                       [output_data3_ne['Lup(W/m2)'].std()*FluxData['Qnet(W/m2)'].std()/FluxData_ne['Lup(W/m2)'].std(), R3_ne['Lup(W/m2)'], \"SIM 3_ne\"],\n",
      "                       [output_data1_dry['Lup(W/m2)'].std()*FluxData['Qnet(W/m2)'].std()/FluxData_dry['Lup(W/m2)'].std(), R1_dry['Lup(W/m2)'], \"SIM 1_dry\"],\n",
      "                       [output_data2_dry['Lup(W/m2)'].std()*FluxData['Qnet(W/m2)'].std()/FluxData_dry['Lup(W/m2)'].std(), R2_dry['Lup(W/m2)'], \"SIM 2_dry\"],\n",
      "                       [output_data3_dry['Lup(W/m2)'].std()*FluxData['Qnet(W/m2)'].std()/FluxData_dry['Lup(W/m2)'].std(), R3_dry['Lup(W/m2)'], \"SIM 3_dry\"],]\n",
      "               )\n",
      "\n",
      "# Colormap (see http://www.scipy.org/Cookbook/Matplotlib/Show_colormaps)\n",
      "colors = [r'orange',r'orange',r'orange',r'blue',r'blue',r'blue',r'red',r'red',r'red',r'green',r'green',r'green',r'orange',r'orange',r'orange',r'blue',r'blue',r'blue',r'red',r'red',r'red',r'green',r'green',r'green']\n",
      "markers = [r's',r'^',r'o',r's',r'^',r'o',r's',r'^',r'o',r's',r'^',r'o',r's',r'^',r'o',r's',r'^',r'o',r's',r'^',r'o',r's',r'^',r'o']\n",
      "# Here set placement of the points marking 95th and 99th significance\n",
      "# levels. For more than 102 samples (degrees freedom > 100), critical\n",
      "# correlation levels are 0.195 and 0.254 for 95th and 99th\n",
      "# significance levels respectively. Set these by eyeball using the\n",
      "# standard deviation x and y axis.\n",
      "\n",
      "#x95 = [0.01, 0.68] # For Tair, this is for 95th level (r = 0.195)\n",
      "#y95 = [0.0, 3.45]\n",
      "#x99 = [0.01, 0.95] # For Tair, this is for 99th level (r = 0.254)\n",
      "#y99 = [0.0, 3.45]\n",
      "\n",
      "x1 = [0.05, np.arccos(0.2)] \n",
      "x2 = [0.05, np.arccos(0.4)]\n",
      "x3 = [0.05, np.arccos(0.6)]\n",
      "x4 = [0.05, np.arccos(0.8)]\n",
      "x5 = [0.05, np.arccos(0.9)]\n",
      "x6 = [0.05, np.arccos(0.99)]\n",
      "y = [0.0, 2.25]\n",
      "\n",
      "\n",
      "rects = dict(QE=221,\n",
      "             QH=222,\n",
      "             QN=223)\n",
      "\n",
      "fig = plt.figure(figsize=(15,12))\n",
      "fig.suptitle(\" \", size='x-large')\n",
      "\n",
      "for season in ['QE','QH','QN']:\n",
      "\n",
      "    dia = TaylorDiagram(stdrefs[season], fig=fig, rect=rects[season],\n",
      "                        label='Reference')\n",
      "    t=np.linspace(0,np.pi/2)\n",
      "    for i in [0.4,0.8,1.2,1.6]:\n",
      "        r=np.zeros_like(t)+i\n",
      "        dia.ax.plot(t,r,'k--')\n",
      "        r1=np.zeros_like(t)+1\n",
      "        dia.ax.plot(t,r1,'r')\n",
      "\n",
      "    dia.ax.plot(x1,y,color='0.5',linestyle='--')\n",
      "    dia.ax.plot(x2,y,color='0.5',linestyle='--')\n",
      "    dia.ax.plot(x3,y,color='0.5',linestyle='--')\n",
      "    dia.ax.plot(x4,y,color='0.5',linestyle='--')\n",
      "    dia.ax.plot(x5,y,color='0.5',linestyle='--')\n",
      "    dia.ax.plot(x6,y,color='0.5',linestyle='--')\n",
      "    \n",
      "    # Add samples to Taylor diagram\n",
      "    for i,(stddev,corrcoef,name) in enumerate(samples[season]):\n",
      "        dia.add_sample(stddev, corrcoef,\n",
      "                       marker=markers[i], ms=8, ls='',\n",
      "                       #mfc='k', mec='k', # B&W\n",
      "                       mfc=colors[i],mec=colors[i], # Colors\n",
      "                       label=name)\n",
      "    \n",
      "    \n",
      "    # Add RMS contours, and label them\n",
      "    contours = dia.add_contours(levels=10,colors='0.5') # 5 levels\n",
      "    #(0.75,0.75),(0.41,1.03),(0.2,1.05)\n",
      "    dia.ax.clabel(contours,inline =1,inline_spacing=0,fontsize=12, fmt='%.1f',colors='k')\n",
      "    # Tricky: ax is the polar ax (used for plots), _ax is the\n",
      "    # container (used for layout)\n",
      "    dia._ax.set_title(names[season])\n",
      "    if season=='QN':\n",
      "        plt.text(0.82,0.24,r'Q$^*$',fontsize=14)\n",
      "        plt.text(1.85,0.67,r'L$\\uparrow$',fontsize=14)\n",
      "     \n",
      "\n",
      "# Add a figure legend and title. For loc option, place x,y tuple inside [ ].\n",
      "# Can also use special options here:\n",
      "# http://matplotlib.sourceforge.net/users/legend_guide.html\n",
      "\n",
      "#fig.legend(dia.samplePoints,\n",
      "#           [ p.get_label() for p in dia.samplePoints ],\n",
      "#           numpoints=1, prop=dict(size='large'), loc='lower right')\n",
      "fig.legend([dia.samplePoints[0],dia.samplePoints[1],dia.samplePoints[2],dia.samplePoints[3],dia.samplePoints[1],dia.samplePoints[4],dia.samplePoints[7],dia.samplePoints[10]],\n",
      "           ['observed','sim_1','sim_2','sim_3','total_period','sw_monsoon','ne_monsoon','dry_period'],\n",
      "           numpoints=1, prop=dict(size='x-large'), bbox_to_anchor=(0.8,0.1),loc='lower right')\n",
      "\n",
      "\n",
      "\n",
      "fig.tight_layout()\n",
      "\n",
      "\n",
      "plt.savefig('taylordiagram.eps', dpi=300,bbox_inches='tight',format='eps')\n",
      "plt.savefig('taylordiagram.jpg', dpi=300,bbox_inches='tight',format='jpg')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Reference std: 48.7893518335\n",
        "Reference std:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 95.944929375\n",
        "Reference std:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 227.6030092\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}